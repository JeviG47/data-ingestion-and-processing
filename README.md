# Data Pipeline Implementation and Management

This repository contains the implementation of a data pipeline for ingesting, transforming, and storing data using Azure services. For detailed documentation, please refer to the [Google Docs Documentation](insert_google_docs_link_here).

## Overview:

The architecture revolves around the following key components:

- Data Generation
- Data Ingestion
- Data Transformation
- Data Storage
- Data Processing

## Setup and Instructions:

To set up and run the data pipeline, follow the instructions below:

1. **Clone the Repository:**

git clone <repository_url>


2. **Install Dependencies:**

pip install -r requirements.txt


3. **Data Generation:**
- Run the data_generation.py script to generate mock user data.


4. **Data Pipeline Setup:**
- Set up Azure Data Factory pipelines for ingestion, transformation, and storage.
- Refer to the [Google Docs Documentation](https://docs.google.com/document/d/15t3EXURh1bVBH5VVmAfBsZjHCf1d8dqW_xZK3PYqw9o/edit?usp=sharing) for detailed setup instructions.

5. **Execute the API:**
- Run the API using uvicorn.


6. **Test CRUD Operations:**
- Use Swagger UI to test CRUD operations and execute complex queries.
- Access Swagger UI at `http://localhost:8000/docs`.

7. **Further Enhancements:**
- For further enhancements and advanced features, refer to the [Google Docs Documentation](https://docs.google.com/document/d/15t3EXURh1bVBH5VVmAfBsZjHCf1d8dqW_xZK3PYqw9o/edit?usp=sharing).

